import warnings
warnings.filterwarnings("ignore")

import logging
from datetime import datetime
import json

import numpy as np
import pandas as pd
import streamlit as st

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.base import clone

import xgboost as xgb

import plotly.graph_objects as go
import plotly.express as px

# -----------------------------------------------------------------------------
# CONFIG STREAMLIT
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="üåç Plateforme Avanc√©e de Mod√©lisation de la D√©forestation",
    page_icon="üå≥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# =============================================================================
# 1. DONN√âES FORESTI√àRES PAR D√âFAUT
# =============================================================================

@st.cache_data(ttl=3600)
def load_default_forest_data():
    """
    Charge un dataset forestier par d√©faut (interpol√© annuellement 2000‚Äì2024).
    Colonnes : Ann√©e, For√™ts Denses (FD), For√™ts Plantation (FP),
    Cultures Annuelles (CA), Cultures P√©rennes (CP), Prairies (P),
    Terrains Habit√©s (TH), Eaux (E), Autres (A), Population, S√©questration CO2.
    """
    base_data = {
        "Ann√©e": [2000, 2005, 2010, 2015, 2020, 2024],
        "For√™ts Denses (FD)": [2935120.85, 2928000.00, 2915092.02, 2885000.00, 2864439.44, 2860127.18],
        "For√™ts Plantation (FP)": [0.0, 5000.00, 8000.00, 20000.00, 34277.61, 35541.06],
        "Cultures Annuelles (CA)": [60056.23, 65000.00, 75187.93, 82000.00, 89736.12, 95863.08],
        "Cultures P√©rennes (CP)": [1681.71, 3000.00, 6365.12, 7000.00, 7412.82, 5109.37],
        "Prairies (P)": [2763.86, 2500.00, 1948.96, 2000.00, 2017.31, 2036.02],
        "Terrains Habit√©s (TH)": [5432.14, 5300.00, 5247.34, 5300.00, 5402.11, 5363.86],
        "Eaux (E)": [9509.11, 10000.00, 10711.23, 10500.00, 10876.27, 10131.16],
        "Autres (A)": [269.94, 275.00, 281.23, 400.00, 672.14, 662.11],
        "Population": [128346, 160000, 224254, 235000, 240915, 247643],
        "S√©questration CO2": [420915, 410000, 399854, 370000, 347443, 329920],
    }

    df_base = pd.DataFrame(base_data)

    years_full = list(range(2000, 2025))
    df_full = pd.DataFrame({"Ann√©e": years_full})

    for col in df_base.columns:
        if col != "Ann√©e":
            df_full[col] = np.interp(
                years_full,
                df_base["Ann√©e"],
                df_base[col]
            )

    return df_full


# =============================================================================
# 2. DONN√âES CLIMATIQUES ONACC (STANDARD)
# =============================================================================

@st.cache_data
def load_onacc_climate_csv(uploaded_file):
    """
    Charge un fichier climat ONACC standard :
    ID_Localit√©, Localit√©, Type_Localit√©, Latitude, Longitude,
    Ann√©e, Precipitation, Temperature, Source_Climat, Scenario_Climat
    """
    df = pd.read_csv(uploaded_file)

    required_cols = [
        "ID_Localit√©", "Localit√©", "Type_Localit√©",
        "Latitude", "Longitude", "Ann√©e",
        "Precipitation", "Temperature",
        "Source_Climat", "Scenario_Climat",
    ]

    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        st.error(f"Colonnes manquantes dans le fichier climat ONACC : {missing}")
        st.stop()

    df["Ann√©e"] = df["Ann√©e"].astype(int)
    df["Precipitation"] = df["Precipitation"].astype(float)
    df["Temperature"] = df["Temperature"].astype(float)

    return df


def merge_climate_data(df_main, df_climate, locality):
    """
    Int√®gre des donn√©es climatiques externes (ONACC) dans le dataset principal.

    df_main : DataFrame principal (forestier) avec une colonne 'Ann√©e'
    df_climate : DataFrame climat ONACC
    locality : nom de la localit√© √† utiliser
    """
    df_clim = df_climate.copy()
    df_clim = df_clim[df_clim["Localit√©"] == locality]

    # Agr√©gation annuelle au cas o√π
    df_clim = (
        df_clim
        .groupby("Ann√©e", as_index=False)[["Precipitation", "Temperature"]]
        .mean()
    )

    df_merged = df_main.merge(df_clim, on="Ann√©e", how="left")
    df_merged["Precipitation"] = df_merged["Precipitation"].interpolate()
    df_merged["Temperature"] = df_merged["Temperature"].interpolate()

    return df_merged


# =============================================================================
# 3. ENRICHISSEMENT DU DATASET
# =============================================================================

def enrich_dataset(df, df_climate=None, locality=None):
    """
    Enrichit le dataset forestier avec :
      - Climat (ERA5/CMIP/ONACC) si fourni, sinon climat simul√©
      - Variables √©conomiques simul√©es
      - Indices composites (pression anthropique, r√©silience)
      - Taux de croissance annuels
    """
    df_enriched = df.copy()

    # 1. Climat : r√©el (ONACC) ou simul√©
    if df_climate is not None and locality is not None:
        df_enriched = merge_climate_data(df_enriched, df_climate, locality)
    else:
        np.random.seed(42)
        df_enriched["Precipitation"] = (
            np.random.normal(1500, 200, len(df_enriched))
            + (df_enriched["Ann√©e"] - df_enriched["Ann√©e"].min()) * 5
        )
        df_enriched["Temperature"] = (
            25 + (df_enriched["Ann√©e"] - df_enriched["Ann√©e"].min()) * 0.02
        )

    # 2. Variables √©conomiques simul√©es
    np.random.seed(42)
    df_enriched["PIB_Agricole"] = (
        df_enriched["Cultures Annuelles (CA)"]
        * np.random.normal(1000, 100, len(df_enriched))
    )
    df_enriched["Investissement_Conservation"] = df_enriched["For√™ts Plantation (FP)"] * 500

    # 3. Indices composites
    df_enriched["Pression_Anthropique"] = (
        df_enriched["Population"] / df_enriched["For√™ts Denses (FD)"] * 1_000_000
    )
    df_enriched["R√©silience_Ecologique"] = (
        df_enriched["For√™ts Plantation (FP)"] / (df_enriched["Cultures Annuelles (CA)"] + 1.0)
    )

    # 4. Taux de changement annuel
    for column in ["For√™ts Denses (FD)", "Population", "Cultures Annuelles (CA)"]:
        df_enriched[f"{column}_Croissance"] = df_enriched[column].pct_change() * 100.0

    return df_enriched


# =============================================================================
# 4. MOD√âLISATION AVANC√âE (CORRIG√âE)
# =============================================================================

def train_advanced_models(df, model_config):
    """
    Entra√Æne plusieurs mod√®les et compare leurs performances.

    df : DataFrame enrichi (incluant au minimum :
         Ann√©e, For√™ts Denses (FD), For√™ts Plantation (FP),
         Cultures Annuelles (CA), Population, S√©questration CO2,
         Temperature, Pression_Anthropique, Precipitation)
    model_config : dict retourn√© par setup_sidebar()
    """
    models = {}

    # Features pour for√™ts denses
    features_fd = [
        "Ann√©e",
        "Population",
        "Cultures Annuelles (CA)",
        "For√™ts Plantation (FP)",
        "Pression_Anthropique",
        "Temperature",
        "Precipitation",
    ]

    # V√©rifier que les features existent
    missing_feats = [f for f in features_fd if f not in df.columns]
    if missing_feats:
        st.error(f"Variables manquantes pour l'entra√Ænement : {missing_feats}")
        st.stop()

    X = df[features_fd]
    y_fd = df["For√™ts Denses (FD)"]
    y_co2 = df["S√©questration CO2"]

    # Param√®tres
    params = model_config.get("model_params", {}) or {}
    use_cv = model_config.get("cross_validation", True)

    # Validation crois√©e temporelle
    tscv = None
    if use_cv and len(df) >= 10:
        n_splits = min(3, max(2, len(df) // 5))
        tscv = TimeSeriesSplit(n_splits=n_splits)

    model_type = model_config.get("model_type", "AutoML")

    if model_type == "R√©gression Lin√©aire":
        model_configs = {"linear": LinearRegression()}

    elif model_type == "Random Forest":
        model_configs = {
            "random_forest": RandomForestRegressor(
                n_estimators=params.get("n_estimators", 100),
                max_depth=params.get("max_depth", None),
                random_state=42,
            )
        }

    elif model_type == "Gradient Boosting":
        model_configs = {
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=params.get("n_estimators", 100),
                max_depth=params.get("max_depth", 3),
                random_state=42,
            )
        }

    elif model_type == "XGBoost":
        model_configs = {
            "xgboost": xgb.XGBRegressor(
                n_estimators=params.get("n_estimators", 100),
                max_depth=params.get("max_depth", 4),
                random_state=42,
            )
        }

    else:  # AutoML
        model_configs = {
            "linear": LinearRegression(),
            "random_forest": RandomForestRegressor(
                n_estimators=100, max_depth=5, random_state=42
            ),
            "gradient_boosting": GradientBoostingRegressor(
                n_estimators=100, max_depth=4, random_state=42
            ),
            "xgboost": xgb.XGBRegressor(
                n_estimators=100, max_depth=4, random_state=42
            ),
        }

    best_score = -np.inf
    best_model_fd = None
    best_model_name = None

    # Entra√Ænement / √©valuation pour FD
    for name, model in model_configs.items():
        cv_scores = None
        mean_score = None

        try:
            if tscv is not None:
                cv_scores = cross_val_score(model, X, y_fd, cv=tscv, scoring="r2")
                mean_score = float(cv_scores.mean())

            model.fit(X, y_fd)

            y_pred = model.predict(X)
            r2 = r2_score(y_fd, y_pred)
            rmse = np.sqrt(mean_squared_error(y_fd, y_pred))
            mae = mean_absolute_error(y_fd, y_pred)

            selection_score = mean_score if mean_score is not None else r2
            if selection_score > best_score:
                best_score = selection_score
                best_model_fd = model
                best_model_name = name

            models[f"fd_{name}"] = {
                "model": model,
                "cv_score": mean_score,
                "r2": r2,
                "rmse": rmse,
                "mae": mae,
                "features": features_fd,
                "cv_scores": cv_scores.tolist() if cv_scores is not None else None,
            }

        except Exception as e:
            st.warning(f"Erreur avec le mod√®le {name} : {e}")
            continue

    # Meilleur mod√®le FD
    if best_model_fd is not None:
        best_model_fd.fit(X, y_fd)
        y_pred_best = best_model_fd.predict(X)

        models["fd_best"] = {
            "model": best_model_fd,
            "name": best_model_name,
            "cv_score": best_score if tscv is not None else None,
            "r2": r2_score(y_fd, y_pred_best),
            "rmse": np.sqrt(mean_squared_error(y_fd, y_pred_best)),
            "mae": mean_absolute_error(y_fd, y_pred_best),
            "features": features_fd,
        }

    # Mod√®le CO2 lin√©aire
    features_co2 = ["Ann√©e", "For√™ts Denses (FD)", "For√™ts Plantation (FP)", "Temperature"]
    missing_co2 = [f for f in features_co2 if f not in df.columns]
    if missing_co2:
        st.error(f"Variables manquantes pour le mod√®le CO2 : {missing_co2}")
        st.stop()

    X_co2 = df[features_co2]
    model_co2 = LinearRegression()
    model_co2.fit(X_co2, y_co2)
    y_pred_co2 = model_co2.predict(X_co2)

    models["co2"] = {
        "model": model_co2,
        "r2": r2_score(y_co2, y_pred_co2),
        "rmse": np.sqrt(mean_squared_error(y_co2, y_pred_co2)),
        "features": features_co2,
    }

    return models


def calculate_confidence_intervals(model, X, y, n_bootstrap=100):
    """
    Calcule les intervalles de confiance par bootstrap.
    Retourne (mean_pred, std_pred).
    """
    predictions = []

    for _ in range(n_bootstrap):
        try:
            indices = np.random.choice(len(X), len(X), replace=True)
            if hasattr(X, "iloc"):
                X_boot = X.iloc[indices]
                y_boot = y.iloc[indices]
            else:
                X_boot = X[indices]
                y_boot = y[indices]

            model_boot = clone(model)
            model_boot.fit(X_boot, y_boot)
            pred = model_boot.predict(X)
            predictions.append(pred)
        except Exception:
            continue

    if len(predictions) == 0:
        base_pred = model.predict(X)
        return base_pred, np.zeros_like(base_pred)

    predictions = np.array(predictions)
    mean_pred = predictions.mean(axis=0)
    std_pred = predictions.std(axis=0)

    return mean_pred, std_pred


# =============================================================================
# 5. INTERFACE UTILISATEUR : SIDEBAR & METRICS
# =============================================================================

def setup_sidebar():
    st.sidebar.title("üéõÔ∏è Panneau de Configuration")

    st.sidebar.subheader("üîß Configuration des Mod√®les")
    model_type = st.sidebar.selectbox(
        "Type de mod√®le :",
        ["R√©gression Lin√©aire", "Random Forest", "Gradient Boosting", "XGBoost", "AutoML"],
    )

    if model_type in ["Random Forest", "Gradient Boosting", "XGBoost"]:
        n_estimators = st.sidebar.slider("Nombre d'arbres", 50, 500, 100)
        max_depth = st.sidebar.slider("Profondeur max", 3, 10, 5)
        model_params = {"n_estimators": n_estimators, "max_depth": max_depth}
    else:
        model_params = {}

    st.sidebar.subheader("üìà Options d'Analyse")
    include_uncertainty = st.sidebar.checkbox("Inclure les intervalles d'incertitude", True)
    cross_validation = st.sidebar.checkbox("Validation crois√©e", True)
    sensitivity_analysis = st.sidebar.checkbox("Analyse de sensibilit√©", False)

    st.sidebar.subheader("üîÆ Sc√©narios")
    default_scenario = st.sidebar.selectbox(
        "Sc√©nario par d√©faut :",
        [
            "SSP1-2.6 - D√©veloppement durable",
            "SSP2-4.5 - Middle of the road",
            "SSP3-7.0 - R√©gional rivalry",
            "SSP5-8.5 - D√©veloppement fossile",
        ],
    )

    return {
        "model_type": model_type,
        "model_params": model_params,
        "include_uncertainty": include_uncertainty,
        "cross_validation": cross_validation,
        "sensitivity_analysis": sensitivity_analysis,
        "default_scenario": default_scenario,
    }


def create_real_time_metrics(df):
    st.subheader("üìä Tableau de Bord des Indicateurs Cl√©s")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        current_fd = df["For√™ts Denses (FD)"].iloc[-1]
        change_fd = current_fd - df["For√™ts Denses (FD)"].iloc[0]
        pct_change_fd = change_fd / df["For√™ts Denses (FD)"].iloc[0] * 100.0
        trend_icon = "üìâ" if change_fd < 0 else "üìà"

        st.metric(
            "For√™ts Denses",
            f"{current_fd:,.0f} Ha {trend_icon}",
            f"{pct_change_fd:+.1f}%",
            delta_color="inverse",
        )

    with col2:
        current_co2 = df["S√©questration CO2"].iloc[-1]
        change_co2 = current_co2 - df["S√©questration CO2"].iloc[0]
        pct_change_co2 = change_co2 / df["S√©questration CO2"].iloc[0] * 100.0
        trend_icon = "üîª" if change_co2 < 0 else "üî∫"

        st.metric(
            "S√©questration CO2",
            f"{current_co2:,.0f} T {trend_icon}",
            f"{pct_change_co2:+.1f}%",
            delta_color="inverse",
        )

    with col3:
        deforestation_rate = (
            df["For√™ts Denses (FD)"].iloc[0] - df["For√™ts Denses (FD)"].iloc[-1]
        ) / (df["Ann√©e"].iloc[-1] - df["Ann√©e"].iloc[0])

        st.metric(
            "Taux D√©forestation Annuel",
            f"{deforestation_rate:,.0f} Ha/an",
            "Moyenne 2000-2024",
        )

    with col4:
        agricultural_pressure = (
            df["Cultures Annuelles (CA)"].iloc[-1]
            / df["For√™ts Denses (FD)"].iloc[-1]
            * 100.0
        )
        pressure_trend = "‚ö†Ô∏è" if agricultural_pressure > 3 else "‚úÖ"

        st.metric(
            "Pression Agricole",
            f"{agricultural_pressure:.2f}% {pressure_trend}",
            "Surface cultiv√©e/for√™t",
        )


# =============================================================================
# 6. VISUALISATIONS : PR√âDICTIONS & CORR√âLATIONS
# =============================================================================

def plot_predictions_with_uncertainty(df, model_info, target_var, include_uncertainty=True):
    model = model_info["model"]
    features = model_info["features"]

    X = df[features]
    y = df[target_var]

    y_pred = model.predict(X)

    fig = go.Figure()

    if include_uncertainty and len(df) > 5:
        try:
            y_mean, y_std = calculate_confidence_intervals(model, X, y)

            fig.add_trace(
                go.Scatter(
                    x=np.concatenate([df["Ann√©e"], df["Ann√©e"][::-1]]),
                    y=np.concatenate(
                        [y_mean - 1.96 * y_std, (y_mean + 1.96 * y_std)[::-1]]
                    ),
                    fill="toself",
                    fillcolor="rgba(0,100,80,0.2)",
                    line=dict(color="rgba(255,255,255,0)"),
                    name="Intervalle de confiance 95%",
                    showlegend=True,
                )
            )

            fig.add_trace(
                go.Scatter(
                    x=df["Ann√©e"],
                    y=y_mean,
                    line=dict(color="rgb(0,100,80)", width=3),
                    mode="lines",
                    name="Pr√©diction moyenne",
                    showlegend=True,
                )
            )
        except Exception as e:
            st.warning(f"Impossible de calculer les intervalles de confiance : {e}")
            fig.add_trace(
                go.Scatter(
                    x=df["Ann√©e"],
                    y=y_pred,
                    line=dict(color="rgb(0,100,80)", width=3),
                    mode="lines",
                    name="Pr√©diction",
                    showlegend=True,
                )
            )
    else:
        fig.add_trace(
            go.Scatter(
                x=df["Ann√©e"],
                y=y_pred,
                line=dict(color="rgb(0,100,80)", width=3),
                mode="lines",
                name="Pr√©diction",
                showlegend=True,
            )
        )

    fig.add_trace(
        go.Scatter(
            x=df["Ann√©e"],
            y=y,
            mode="markers+lines",
            marker=dict(color="red", size=8),
            line=dict(color="red", width=2, dash="dash"),
            name="Observations",
            showlegend=True,
        )
    )

    fig.update_layout(
        title=f"Pr√©dictions {target_var} avec Intervalles de Confiance",
        xaxis_title="Ann√©e",
        yaxis_title=target_var,
        height=500,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )

    return fig


def create_advanced_correlation_matrix(df):
    st.subheader("üîó Analyse des Corr√©lations Avanc√©e")

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    selected_vars = st.multiselect(
        "S√©lectionnez les variables pour l'analyse de corr√©lation :",
        options=numeric_cols,
        default=numeric_cols[:8],
    )

    if len(selected_vars) < 2:
        st.warning("Veuillez s√©lectionner au moins 2 variables.")
        return

    corr_data = df[selected_vars]
    corr_matrix = corr_data.corr()

    fig = px.imshow(
        corr_matrix,
        text_auto=True,
        aspect="auto",
        color_continuous_scale="RdBu_r",
        title="Matrice de Corr√©lation Interactive",
    )
    fig.update_layout(height=600)
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("Corr√©lations Significatives (|r| > 0.7)")
    strong_correlations = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i + 1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.7:
                strong_correlations.append(
                    {
                        "Variable 1": corr_matrix.columns[i],
                        "Variable 2": corr_matrix.columns[j],
                        "Corr√©lation": f"{corr_val:.3f}",
                        "Type": "Forte positive" if corr_val > 0 else "Forte n√©gative",
                    }
                )

    if strong_correlations:
        strong_corr_df = pd.DataFrame(strong_correlations)
        st.dataframe(strong_corr_df, use_container_width=True)
    else:
        st.info("Aucune corr√©lation forte (|r| > 0.7) identifi√©e.")


# =============================================================================
# 7. SC√âNARIOS GIEC AVEC INCERTITUDES
# =============================================================================

class ScenarioManager:
    def __init__(self, base_year=2024):
        self.base_year = base_year
        self.scenarios = self.initialize_giec_scenarios()

    def initialize_giec_scenarios(self):
        return {
            "SSP1-2.6 - D√©veloppement durable": {
                "pop_growth": 0.008,
                "agri_growth": -0.005,
                "conservation_effort": 0.03,
                "tech_improvement": 0.02,
                "climate_impact": -0.001,
                "economic_growth": 0.025,
                "temp_increase": "1.5-2.0¬∞C",
                "description": "Transition rapide vers la durabilit√©, forte protection des for√™ts, √©conomie circulaire",
            },
            "SSP2-4.5 - Middle of the road": {
                "pop_growth": 0.012,
                "agri_growth": 0.008,
                "conservation_effort": 0.01,
                "tech_improvement": 0.01,
                "climate_impact": -0.003,
                "economic_growth": 0.03,
                "temp_increase": "2.0-3.0¬∞C",
                "description": "Continuit√© des tendances actuelles, mesures environnementales mod√©r√©es",
            },
            "SSP3-7.0 - R√©gional rivalry": {
                "pop_growth": 0.018,
                "agri_growth": 0.015,
                "conservation_effort": -0.01,
                "tech_improvement": 0.005,
                "climate_impact": -0.008,
                "economic_growth": 0.02,
                "temp_increase": "3.0-4.0¬∞C",
                "description": "Fortes pressions, faible coop√©ration internationale, fragmentation",
            },
            "SSP5-8.5 - D√©veloppement fossile": {
                "pop_growth": 0.015,
                "agri_growth": 0.025,
                "conservation_effort": -0.02,
                "tech_improvement": 0.015,
                "climate_impact": -0.015,
                "economic_growth": 0.035,
                "temp_increase": "4.0-5.0¬∞C",
                "description": "Croissance √©conomique forte bas√©e sur les √©nergies fossiles, exploitation intensive",
            },
        }

    def simulate_scenario(self, scenario_name, models, df, target_year, n_simulations=100):
        if "fd_best" not in models:
            raise ValueError("Le mod√®le 'fd_best' n'est pas disponible.")
        if "co2" not in models:
            raise ValueError("Le mod√®le 'co2' n'est pas disponible.")

        scenario = self.scenarios[scenario_name]
        results = []

        last_year = df["Ann√©e"].iloc[-1]
        last_pop = df["Population"].iloc[-1]
        last_agri = df["Cultures Annuelles (CA)"].iloc[-1]
        last_fp = df["For√™ts Plantation (FP)"].iloc[-1]
        last_fd = df["For√™ts Denses (FD)"].iloc[-1]
        last_temp = df["Temperature"].iloc[-1]
        last_prec = df.get("Precipitation", pd.Series([0])).iloc[-1]

        model_fd = models["fd_best"]["model"]
        features_fd = models["fd_best"]["features"]

        model_co2 = models["co2"]["model"]
        features_co2 = models["co2"]["features"]

        years_ahead = max(0, target_year - last_year)

        for _ in range(n_simulations):
            pop_var = np.random.normal(1, 0.1)
            agri_var = np.random.normal(1, 0.15)
            conserv_var = np.random.normal(1, 0.2)
            tech_var = np.random.normal(1, 0.1)

            future_pop = last_pop * (1 + scenario["pop_growth"] * pop_var) ** years_ahead
            future_agri = last_agri * (1 + scenario["agri_growth"] * agri_var) ** years_ahead
            future_fp = last_fp * (1 + scenario["conservation_effort"] * conserv_var) ** years_ahead

            future_temp = last_temp + years_ahead * 0.02
            future_prec = last_prec  # simplification (on pourrait extrapoler)

            approx_fd_for_pressure = max(last_fd, 1.0)
            future_pressure = (future_pop / approx_fd_for_pressure) * 1_000_000

            # Features FD
            feature_values_fd = []
            for feat in features_fd:
                if feat == "Ann√©e":
                    val = target_year
                elif feat == "Population":
                    val = future_pop
                elif feat == "Cultures Annuelles (CA)":
                    val = future_agri
                elif feat == "For√™ts Plantation (FP)":
                    val = future_fp
                elif feat == "Pression_Anthropique":
                    val = future_pressure
                elif feat == "Temperature":
                    val = future_temp
                elif feat == "Precipitation":
                    val = future_prec
                else:
                    val = df[feat].iloc[-1] if feat in df.columns else 0.0
                feature_values_fd.append(val)

            X_future_fd = np.array([feature_values_fd])
            future_fd_base = float(model_fd.predict(X_future_fd)[0])

            conservation_impact = scenario["conservation_effort"] * last_fd * years_ahead / 5.0
            tech_impact = scenario["tech_improvement"] * tech_var * last_fd * years_ahead / 20.0
            climate_impact = scenario["climate_impact"] * last_fd * years_ahead

            future_fd_adj = future_fd_base + conservation_impact + tech_impact + climate_impact
            future_fd_adj = max(future_fd_adj, 0.0)

            future_pressure_for_co2 = (future_pop / max(future_fd_adj, 1.0)) * 1_000_000

            # Features CO2
            feature_values_co2 = []
            for feat in features_co2:
                if feat == "Ann√©e":
                    val = target_year
                elif feat == "For√™ts Denses (FD)":
                    val = future_fd_adj
                elif feat == "For√™ts Plantation (FP)":
                    val = future_fp
                elif feat == "Temperature":
                    val = future_temp
                else:
                    val = df[feat].iloc[-1] if feat in df.columns else 0.0
                feature_values_co2.append(val)

            X_future_co2 = np.array([feature_values_co2])
            future_co2 = float(model_co2.predict(X_future_co2)[0])

            results.append(
                {
                    "scenario": scenario_name,
                    "population": future_pop,
                    "agriculture": future_agri,
                    "forest_plantation": future_fp,
                    "forest_dense": future_fd_adj,
                    "co2_sequestration": future_co2,
                    "year": target_year,
                }
            )

        return pd.DataFrame(results)


# =============================================================================
# 8. MODULES CLIMAT : DIAGNOSTICS & MULTI-LOCALIT√âS
# =============================================================================

def climate_diagnostics(df_enriched, locality_name=None):
    st.subheader("üå¶ Diagnostics climatiques")

    col1, col2 = st.columns(2)
    with col1:
        fig_temp = px.line(
            df_enriched,
            x="Ann√©e",
            y="Temperature",
            title=f"Temp√©rature moyenne annuelle{f' - {locality_name}' if locality_name else ''}",
        )
        st.plotly_chart(fig_temp, use_container_width=True)

    with col2:
        fig_prec = px.line(
            df_enriched,
            x="Ann√©e",
            y="Precipitation",
            title=f"Pr√©cipitations annuelles{f' - {locality_name}' if locality_name else ''}",
        )
        st.plotly_chart(fig_prec, use_container_width=True)

    st.markdown("**Anomalies climatiques (r√©f√©rence 2000‚Äì2010)**")
    ref_mask = (df_enriched["Ann√©e"] >= 2000) & (df_enriched["Ann√©e"] <= 2010)

    if ref_mask.any():
        ref_temp = df_enriched.loc[ref_mask, "Temperature"].mean()
        ref_prec = df_enriched.loc[ref_mask, "Precipitation"].mean()

        df_anom = df_enriched.copy()
        df_anom["Temp_Anom"] = df_anom["Temperature"] - ref_temp
        df_anom["Prec_Anom_%"] = (df_anom["Precipitation"] - ref_prec) / ref_prec * 100.0

        col3, col4 = st.columns(2)
        with col3:
            fig_anom_t = px.bar(
                df_anom,
                x="Ann√©e",
                y="Temp_Anom",
                title="Anomalies de temp√©rature (¬∞C)",
            )
            st.plotly_chart(fig_anom_t, use_container_width=True)

        with col4:
            fig_anom_p = px.bar(
                df_anom,
                x="Ann√©e",
                y="Prec_Anom_%",
                title="Anomalies de pr√©cipitations (%)",
            )
            st.plotly_chart(fig_anom_p, use_container_width=True)
    else:
        st.info("P√©riode de r√©f√©rence 2000‚Äì2010 non disponible pour les anomalies.")


def multi_locality_dashboard(df_climate, df_forest=None, selected_localities=None):
    if not selected_localities:
        st.info("Veuillez s√©lectionner au moins une localit√© dans la barre lat√©rale.")
        return

    st.header("üåç Analyse Multi-Localit√©s")

    dfc = df_climate[df_climate["Localit√©"].isin(selected_localities)].copy()

    # Temp√©rature
    st.subheader("üå°Ô∏è Temp√©rature moyenne annuelle ‚Äì comparaison")
    fig_temp = px.line(
        dfc,
        x="Ann√©e",
        y="Temperature",
        color="Localit√©",
        line_group="Localit√©",
        markers=True,
        hover_data=["Source_Climat", "Scenario_Climat"],
        title="Temp√©rature moyenne annuelle par localit√©",
    )
    st.plotly_chart(fig_temp, use_container_width=True)

    # Pr√©cipitations
    st.subheader("üåßÔ∏è Pr√©cipitations annuelles ‚Äì comparaison")
    fig_prec = px.line(
        dfc,
        x="Ann√©e",
        y="Precipitation",
        color="Localit√©",
        line_group="Localit√©",
        markers=True,
        hover_data=["Source_Climat", "Scenario_Climat"],
        title="Pr√©cipitations annuelles par localit√©",
    )
    st.plotly_chart(fig_prec, use_container_width=True)

    # Anomalies
    st.subheader("üìä Anomalies climatiques par rapport √† 2000‚Äì2010")
    ref_mask = (dfc["Ann√©e"] >= 2000) & (dfc["Ann√©e"] <= 2010)

    if ref_mask.any():
        ref_means = (
            dfc[ref_mask]
            .groupby("Localit√©")[["Temperature", "Precipitation"]]
            .mean()
            .rename(columns={"Temperature": "Temp_Ref", "Precipitation": "Prec_Ref"})
        )

        dfc = dfc.merge(ref_means, on="Localit√©", how="left")
        dfc["Temp_Anom"] = dfc["Temperature"] - dfc["Temp_Ref"]
        dfc["Prec_Anom_%"] = (dfc["Precipitation"] - dfc["Prec_Ref"]) / dfc["Prec_Ref"] * 100.0

        col1, col2 = st.columns(2)
        with col1:
            fig_anom_t = px.bar(
                dfc,
                x="Ann√©e",
                y="Temp_Anom",
                color="Localit√©",
                barmode="group",
                title="Anomalies de temp√©rature (¬∞C)",
            )
            st.plotly_chart(fig_anom_t, use_container_width=True)
        with col2:
            fig_anom_p = px.bar(
                dfc,
                x="Ann√©e",
                y="Prec_Anom_%",
                color="Localit√©",
                barmode="group",
                title="Anomalies de pr√©cipitations (%)",
            )
            st.plotly_chart(fig_anom_p, use_container_width=True)
    else:
        st.info("P√©riode 2000‚Äì2010 non couverte dans les donn√©es climat.")

    # For√™ts (facultatif si tu as un fichier forestier multi-localit√©s)
    if df_forest is not None and "Localit√©" in df_forest.columns:
        st.subheader("üå≥ For√™ts denses ‚Äì comparaison (si disponible)")
        dff = df_forest[df_forest["Localit√©"].isin(selected_localities)].copy()
        fig_fd = px.line(
            dff,
            x="Ann√©e",
            y="For√™ts Denses (FD)",
            color="Localit√©",
            markers=True,
            title="For√™ts denses par localit√©",
        )
        st.plotly_chart(fig_fd, use_container_width=True)


# =============================================================================
# 9. APPLICATION PRINCIPALE
# =============================================================================

def main():
    st.title("üåç Plateforme Avanc√©e de Mod√©lisation de la D√©forestation")
    st.markdown(
        """
    **Analyse scientifique des dynamiques de d√©forestation int√©grant mod√©lisation avanc√©e, 
    sc√©narios GIEC et analyse d'incertitude pour une prise de d√©cision √©clair√©e.**
    """
    )

    # Session state
    if "models_trained" not in st.session_state:
        st.session_state.models_trained = False
    if "current_models" not in st.session_state:
        st.session_state.current_models = None
    if "scenario_results" not in st.session_state:
        st.session_state.scenario_results = {}

    # Mode : une localit√© / multi-localit√©s
    st.sidebar.title("Mode d'analyse")
    mode_localites = st.sidebar.radio(
        "S√©lection du mode :", ["Une localit√©", "Multi-localit√©s"], index=0
    )

    # -------------------------------------------------------------------------
    # Donn√©es foresti√®res
    # -------------------------------------------------------------------------
    st.sidebar.subheader("üå≥ Donn√©es foresti√®res")
    forest_file = st.sidebar.file_uploader(
        "Fichier forestier (optionnel, CSV)",
        type=["csv"],
        help="Si non fourni, les donn√©es par d√©faut 2000‚Äì2024 seront utilis√©es.",
    )

    if forest_file is not None:
        df_forest_raw = pd.read_csv(forest_file)
        if "Ann√©e" not in df_forest_raw.columns:
            st.warning("Le fichier forestier doit contenir une colonne 'Ann√©e'.")
            df_forest = load_default_forest_data()
        else:
            df_forest = df_forest_raw.sort_values("Ann√©e").reset_index(drop=True)
    else:
        df_forest = load_default_forest_data()

    # -------------------------------------------------------------------------
    # Donn√©es climatiques ONACC
    # -------------------------------------------------------------------------
    st.sidebar.subheader("üå¶ Donn√©es climatiques (ONACC)")
    climate_file = st.sidebar.file_uploader(
        "Fichier climate_data_onacc.csv (optionnel)",
        type=["csv"],
        help="Utilise le standard ONACC propos√© (Ann√©e, Localit√©, Precipitation, Temperature, ...).",
    )

    df_climate = None
    selected_localities = None

    if climate_file is not None:
        df_climate = load_onacc_climate_csv(climate_file)
        all_localities = df_climate["Localit√©"].unique().tolist()

        if mode_localites == "Multi-localit√©s":
            selected_localities = st.sidebar.multiselect(
                "Localit√©s √† analyser",
                options=all_localities,
                default=all_localities[: min(3, len(all_localities))],
            )
        else:
            selected_locality_single = st.sidebar.selectbox(
                "Localit√© √† analyser", options=all_localities
            )
            selected_localities = [selected_locality_single]
    else:
        st.sidebar.info("Aucun fichier climat ONACC charg√© ‚Üí climat simul√©.")

    # -------------------------------------------------------------------------
    # Mode Multi-localit√©s : seulement vue comparative climat/for√™ts
    # -------------------------------------------------------------------------
    if mode_localites == "Multi-localit√©s":
        if df_climate is None:
            st.warning(
                "Le mode multi-localit√©s n√©cessite un fichier climat ONACC. "
                "Veuillez en charger un dans la barre lat√©rale."
            )
            return

        multi_locality_dashboard(df_climate, df_forest=None, selected_localities=selected_localities)
        return

    # -------------------------------------------------------------------------
    # Mode Une localit√© : pipeline complet (mod√©lisation, sc√©narios, etc.)
    # -------------------------------------------------------------------------
    if df_climate is not None:
        locality_name = selected_localities[0]
    else:
        locality_name = None

    df_forest = df_forest.sort_values("Ann√©e").reset_index(drop=True)

    with st.spinner("üîÑ Enrichissement des donn√©es..."):
        df_enriched = enrich_dataset(df_forest, df_climate, locality_name)

    # Configuration de la sidebar (mod√®les, incertitude, sc√©narios)
    config = setup_sidebar()

    # Dashboard indicateurs
    create_real_time_metrics(df_enriched)

    # Navigation sections
    st.sidebar.title("Navigation")
    page = st.sidebar.radio(
        "Sections",
        [
            "üìä Donn√©es et Exploration",
            "ü§ñ Mod√©lisation Avanc√©e",
            "üîÆ Sc√©narios GIEC avec Incertitudes",
            "üìà Analyse de Sensibilit√©",
            "üìã Rapport Scientifique",
        ],
    )

    # -------------------------------------------------------------------------
    # Section 1 : Donn√©es & Exploration
    # -------------------------------------------------------------------------
    if page == "üìä Donn√©es et Exploration":
        st.header("üìä Exploration Avanc√©e des Donn√©es")

        col1, col2 = st.columns([1, 2])
        with col1:
            st.subheader("Dataset Enrichi")
            st.dataframe(df_enriched.style.format("{:,.2f}"), use_container_width=True)

            st.subheader("Statistiques Descriptives")
            st.dataframe(df_enriched.describe(), use_container_width=True)

            csv = df_enriched.to_csv(index=False)
            st.download_button(
                label="üì• T√©l√©charger le dataset complet CSV",
                data=csv,
                file_name="donnees_deforestation_enrichies.csv",
                mime="text/csv",
            )

        with col2:
            st.subheader("Visualisations Multiples")

            indicators = st.multiselect(
                "S√©lectionnez les indicateurs √† visualiser :",
                options=df_enriched.columns[1:],
                default=[
                    "For√™ts Denses (FD)",
                    "Population",
                    "S√©questration CO2",
                    "Cultures Annuelles (CA)",
                ],
            )

            if indicators:
                fig = go.Figure()
                colors = px.colors.qualitative.Set3
                for i, indicator in enumerate(indicators):
                    fig.add_trace(
                        go.Scatter(
                            x=df_enriched["Ann√©e"],
                            y=df_enriched[indicator],
                            mode="lines+markers",
                            name=indicator,
                            line=dict(color=colors[i % len(colors)], width=3),
                        )
                    )
                fig.update_layout(
                    title="√âvolution des Indicateurs Cl√©s",
                    xaxis_title="Ann√©e",
                    height=500,
                )
                st.plotly_chart(fig, use_container_width=True)

            # Matrice de corr√©lation
            create_advanced_correlation_matrix(df_enriched)

            # Diagnostics climat
            if df_climate is not None and locality_name is not None:
                climate_diagnostics(df_enriched, locality_name=locality_name)

    # -------------------------------------------------------------------------
    # Section 2 : Mod√©lisation Avanc√©e
    # -------------------------------------------------------------------------
    elif page == "ü§ñ Mod√©lisation Avanc√©e":
        st.header("ü§ñ Mod√©lisation Pr√©dictive Avanc√©e")

        if (not st.session_state.models_trained) or st.button("üîÑ R√©entra√Æner les mod√®les"):
            with st.spinner("Entra√Ænement des mod√®les en cours..."):
                try:
                    models = train_advanced_models(df_enriched, config)
                    st.session_state.current_models = models
                    st.session_state.models_trained = True
                    st.success("‚úÖ Mod√®les entra√Æn√©s avec succ√®s !")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'entra√Ænement : {e}")
                    return

        if st.session_state.models_trained:
            models = st.session_state.current_models

            st.subheader("üìä Performance des Mod√®les")

            if (
                config["model_type"] == "AutoML"
                and any(k.startswith("fd_") for k in models.keys())
            ):
                model_comparison = []
                for key, model_info in models.items():
                    if key.startswith("fd_") and key != "fd_best":
                        model_comparison.append(
                            {
                                "Mod√®le": key.replace("fd_", ""),
                                "R¬≤": model_info["r2"],
                                "RMSE": model_info["rmse"],
                                "MAE": model_info["mae"],
                                "CV Score": model_info["cv_score"],
                            }
                        )
                if model_comparison:
                    comparison_df = pd.DataFrame(model_comparison)
                    st.dataframe(
                        comparison_df.style.format(
                            {
                                "R¬≤": "{:.4f}",
                                "RMSE": "{:,.0f}",
                                "MAE": "{:,.0f}",
                                "CV Score": "{:.4f}",
                            }
                        ),
                        use_container_width=True,
                    )

            if "fd_best" in models:
                best_model_info = models["fd_best"]
                st.subheader(
                    f"üéØ Meilleur Mod√®le : {best_model_info.get('name', 'Linear Regression')}"
                )

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("R¬≤", f"{best_model_info['r2']:.4f}")
                with col2:
                    st.metric("RMSE", f"{best_model_info['rmse']:,.0f}")
                with col3:
                    st.metric("MAE", f"{best_model_info['mae']:,.0f}")
                with col4:
                    st.metric(
                        "Score CV",
                        f"{(best_model_info.get('cv_score') or 0.0):.4f}",
                    )

                st.subheader("üìà Pr√©dictions avec Intervalles de Confiance")
                fig_fd = plot_predictions_with_uncertainty(
                    df_enriched,
                    best_model_info,
                    "For√™ts Denses (FD)",
                    config["include_uncertainty"],
                )
                st.plotly_chart(fig_fd, use_container_width=True)

                if hasattr(best_model_info["model"], "feature_importances_"):
                    st.subheader("üìä Importance des Variables")
                    feature_importance = pd.DataFrame(
                        {
                            "Variable": best_model_info["features"],
                            "Importance": best_model_info["model"].feature_importances_,
                        }
                    ).sort_values("Importance", ascending=True)

                    fig_importance = px.bar(
                        feature_importance,
                        x="Importance",
                        y="Variable",
                        orientation="h",
                        title="Importance Relative des Variables",
                    )
                    st.plotly_chart(fig_importance, use_container_width=True)

    # -------------------------------------------------------------------------
    # Section 3 : Sc√©narios GIEC avec Incertitudes
    # -------------------------------------------------------------------------
    elif page == "üîÆ Sc√©narios GIEC avec Incertitudes":
        st.header("üîÆ Simulation de Sc√©narios GIEC avec Analyse d'Incertitude")

        if not st.session_state.models_trained:
            st.warning("‚ö†Ô∏è Veuillez d'abord entra√Æner les mod√®les dans 'Mod√©lisation Avanc√©e'.")
            return

        models = st.session_state.current_models
        scenario_manager = ScenarioManager()

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("Configuration des Sc√©narios")
            target_year = st.slider("Horizon temporel", 2025, 2100, 2050)

            selected_scenarios = st.multiselect(
                "Sc√©narios GIEC √† simuler :",
                options=list(scenario_manager.scenarios.keys()),
                default=[config["default_scenario"]],
            )

            n_simulations = st.slider("Nombre de simulations Monte Carlo", 50, 1000, 100)

            if st.button("üöÄ Lancer les Simulations"):
                with st.spinner(
                    f"Simulation de {len(selected_scenarios)} sc√©narios ({n_simulations} tirages chacun)..."
                ):
                    st.session_state.scenario_results = {}
                    for scenario_name in selected_scenarios:
                        results = scenario_manager.simulate_scenario(
                            scenario_name, models, df_enriched, target_year, n_simulations
                        )
                        st.session_state.scenario_results[scenario_name] = results
                    st.success("‚úÖ Simulations termin√©es !")

        with col2:
            st.subheader("R√©sultats des Simulations")

            if not st.session_state.scenario_results:
                st.info("Veuillez lancer les simulations pour voir les r√©sultats.")
            else:
                summary_data = []
                for scenario_name, results in st.session_state.scenario_results.items():
                    fd_mean = results["forest_dense"].mean()
                    fd_std = results["forest_dense"].std()
                    co2_mean = results["co2_sequestration"].mean()

                    current_fd = df_enriched["For√™ts Denses (FD)"].iloc[-1]
                    current_co2 = df_enriched["S√©questration CO2"].iloc[-1]

                    fd_change_pct = (fd_mean - current_fd) / current_fd * 100.0
                    co2_change_pct = (co2_mean - current_co2) / current_co2 * 100.0

                    summary_data.append(
                        {
                            "Sc√©nario": scenario_name,
                            "For√™ts (Moy)": f"{fd_mean:,.0f}",
                            "¬± Incertitude": f"¬±{fd_std:,.0f}",
                            "Œî For√™ts (%)": f"{fd_change_pct:+.1f}%",
                            "Œî CO2 (%)": f"{co2_change_pct:+.1f}%",
                        }
                    )

                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True)

        if st.session_state.scenario_results:
            st.subheader("üìä Comparaison Visuelle des Sc√©narios")
            fig_comparison = go.Figure()
            colors = px.colors.qualitative.Bold

            for i, (scenario_name, results) in enumerate(
                st.session_state.scenario_results.items()
            ):
                fig_comparison.add_trace(
                    go.Box(
                        y=results["forest_dense"],
                        name=scenario_name,
                        marker_color=colors[i % len(colors)],
                        boxpoints="outliers",
                    )
                )

            fig_comparison.update_layout(
                title="Distribution des Projections de For√™ts Denses par Sc√©nario",
                yaxis_title="For√™ts Denses (Ha)",
                height=500,
            )
            st.plotly_chart(fig_comparison, use_container_width=True)

            st.subheader("üïê √âvolution Temporelle des Sc√©narios")
            selected_scenario = st.selectbox(
                "Sc√©nario pour l'√©volution d√©taill√©e :",
                options=list(st.session_state.scenario_results.keys()),
            )

            if selected_scenario:
                years_proj = list(range(df_enriched["Ann√©e"].iloc[-1], target_year + 1, 5))
                fd_proj = []
                fd_min = []
                fd_max = []

                for year in years_proj:
                    results = scenario_manager.simulate_scenario(
                        selected_scenario, models, df_enriched, year, 50
                    )
                    fd_proj.append(results["forest_dense"].mean())
                    fd_min.append(results["forest_dense"].quantile(0.05))
                    fd_max.append(results["forest_dense"].quantile(0.95))

                fig_evolution = go.Figure()
                fig_evolution.add_trace(
                    go.Scatter(
                        x=years_proj + years_proj[::-1],
                        y=fd_max + fd_min[::-1],
                        fill="toself",
                        fillcolor="rgba(0,100,80,0.2)",
                        line=dict(color="rgba(255,255,255,0)"),
                        name="Intervalle de confiance 90%",
                    )
                )
                fig_evolution.add_trace(
                    go.Scatter(
                        x=years_proj,
                        y=fd_proj,
                        line=dict(color="rgb(0,100,80)", width=3),
                        mode="lines+markers",
                        name="Projection moyenne",
                    )
                )
                fig_evolution.add_trace(
                    go.Scatter(
                        x=df_enriched["Ann√©e"],
                        y=df_enriched["For√™ts Denses (FD)"],
                        line=dict(color="red", width=2),
                        mode="lines+markers",
                        name="Historique",
                    )
                )
                fig_evolution.update_layout(
                    title=f"√âvolution des For√™ts Denses - {selected_scenario}",
                    xaxis_title="Ann√©e",
                    yaxis_title="For√™ts Denses (Ha)",
                    height=500,
                )
                st.plotly_chart(fig_evolution, use_container_width=True)

    # -------------------------------------------------------------------------
    # Section 4 : Analyse de Sensibilit√©
    # -------------------------------------------------------------------------
    elif page == "üìà Analyse de Sensibilit√©":
        st.header("üìà Analyse de Sensibilit√© Globale")

        if not st.session_state.models_trained:
            st.warning("‚ö†Ô∏è Veuillez d'abord entra√Æner les mod√®les.")
            return

        models = st.session_state.current_models
        if "fd_best" not in models:
            st.warning("Aucun mod√®le 'fd_best' disponible.")
            return

        model_info = models["fd_best"]
        model = model_info["model"]
        features = model_info["features"]

        st.subheader("üéØ Analyse de l'Impact des Variables d'Entr√©e")

        base_values = {}
        for feature in features:
            if feature in df_enriched.columns:
                base_values[feature] = df_enriched[feature].iloc[-1]
            else:
                base_values[feature] = 0.0

        X_base = np.array([list(base_values.values())])
        base_prediction = model.predict(X_base)[0]

        sensitivity_results = {}
        perturbations = [-0.2, -0.1, -0.05, 0.05, 0.1, 0.2]

        for feature in features:
            changes = []
            for pert in perturbations:
                perturbed_values = base_values.copy()
                perturbed_values[feature] *= (1 + pert)

                X_pert = np.array([list(perturbed_values.values())])
                try:
                    prediction = model.predict(X_pert)[0]
                    change_pct = (prediction - base_prediction) / base_prediction * 100.0
                    changes.append(
                        {
                            "Perturbation": pert * 100.0,
                            "Pr√©diction": prediction,
                            "Changement %": change_pct,
                        }
                    )
                except Exception:
                    continue

            if changes:
                sensitivity_results[feature] = pd.DataFrame(changes)

        if sensitivity_results:
            fig_sensitivity = go.Figure()
            colors = px.colors.qualitative.Set3
            for i, (feature, data) in enumerate(sensitivity_results.items()):
                fig_sensitivity.add_trace(
                    go.Scatter(
                        x=data["Perturbation"],
                        y=data["Changement %"],
                        mode="lines+markers",
                        name=feature,
                        line=dict(color=colors[i % len(colors)], width=3),
                    )
                )
            fig_sensitivity.update_layout(
                title="Analyse de Sensibilit√© - Impact sur les For√™ts Denses",
                xaxis_title="Perturbation des Variables d'Entr√©e (%)",
                yaxis_title="Changement dans la Pr√©diction (%)",
                height=500,
            )
            st.plotly_chart(fig_sensitivity, use_container_width=True)

            st.subheader("üìã Sensibilit√© par Variable")
            sensitivity_summary = []
            for feature, data in sensitivity_results.items():
                max_effect = data["Changement %"].abs().max()
                sensitivity_summary.append(
                    {
                        "Variable": feature,
                        "Impact Max (%)": f"{max_effect:.2f}%",
                        "Sensibilit√©": "√âlev√©e"
                        if max_effect > 5
                        else "Mod√©r√©e"
                        if max_effect > 2
                        else "Faible",
                    }
                )
            sensitivity_df = pd.DataFrame(sensitivity_summary)
            st.dataframe(sensitivity_df, use_container_width=True)
        else:
            st.info("Impossible de calculer la sensibilit√© avec les param√®tres actuels.")

    # -------------------------------------------------------------------------
    # Section 5 : Rapport Scientifique
    # -------------------------------------------------------------------------
    else:
        st.header("üìã Rapport Scientifique Complet")

        st.subheader("üéØ R√©sum√© Ex√©cutif")
        col1, col2 = st.columns(2)

        total_deforestation = (
            df_enriched["For√™ts Denses (FD)"].iloc[0] - df_enriched["For√™ts Denses (FD)"].iloc[-1]
        )
        annual_rate = total_deforestation / (
            df_enriched["Ann√©e"].iloc[-1] - df_enriched["Ann√©e"].iloc[0]
        )

        with col1:
            st.markdown(
                """
            **Objectifs de la Recherche :**
            - ‚úÖ Analyse multidimensionnelle des dynamiques de d√©forestation
            - ‚úÖ Mod√©lisation avanc√©e avec validation rigoureuse
            - ‚úÖ Int√©gration des sc√©narios GIEC SSP-RCP
            - ‚úÖ Quantification des incertitudes et analyse de sensibilit√©
            - ‚úÖ Recommandations politiques fond√©es sur des preuves
            """
            )
            st.metric("D√©forestation totale 2000-2024", f"{total_deforestation:,.0f} Ha")
            st.metric("Taux annuel moyen", f"{annual_rate:,.0f} Ha/an")

        with col2:
            st.markdown(
                """
            **M√©thodologie Avanc√©e :**
            - üî¨ Interpolation temporelle et enrichissement des donn√©es
            - ü§ñ Mod√©lisation par ensemble (Random Forest, XGBoost, etc.)
            - üìä Validation crois√©e temporelle
            - üé≤ Analyse Monte Carlo pour les incertitudes
            - üìà Analyse de sensibilit√© globale
            """
            )
            if st.session_state.models_trained and "fd_best" in st.session_state.current_models:
                best_model = st.session_state.current_models["fd_best"]
                st.metric("Performance du meilleur mod√®le (R¬≤)", f"{best_model['r2']:.4f}")

        st.subheader("üéØ Recommandations Strat√©giques")

        tab1, tab2, tab3 = st.tabs(
            ["üéØ Court Terme (2024-2030)", "üìà Moyen Terme (2031-2040)", "üå≥ Long Terme (2041-2050)"]
        )
        with tab1:
            st.markdown(
                """
            **Actions Prioritaires Imm√©diates :**
            - üõë Moratoire cibl√© sur la conversion des for√™ts primaires
            - üåæ Intensification durable de l'agriculture existante
            - üìä Syst√®me de monitoring en temps r√©el
            - üí∞ Paiements pour services √©cosyst√©miques
            - üìö Programmes d'√©ducation environnementale
            - üîÑ Diversification des revenus ruraux
            """
            )
        with tab2:
            st.markdown(
                """
            **Strat√©gies de Transition 2031-2040 :**
            - üåø Restauration √©cologique des zones d√©grad√©es
            - üèôÔ∏è Plan d'urbanisation ma√Ætris√©
            - üîã Transition √©nerg√©tique vers les renouvelables
            - ü§ù Coop√©ration r√©gionale pour la gestion des bassins versants
            - üìà √âconomie verte cr√©atrice d'emplois
            - üî¨ Innovation technologique agricole et foresti√®re
            """
            )
        with tab3:
            st.markdown(
                """
            **Vision Durable 2041-2050 :**
            - üåç √âconomie d√©carbon√©e et circulaire
            - üèûÔ∏è Connectivit√© √©cologique restaur√©e
            - üë• Gouvernance participative institutionnalis√©e
            - üîÑ R√©silience climatique int√©gr√©e aux politiques
            - üí° Innovation sociale et entrepreneuriat vert
            - üìä Comptabilit√© environnementale g√©n√©ralis√©e
            """
            )

        st.subheader("üìÑ Export du Rapport Complet")
        if st.button("üìä G√©n√©rer le Rapport D√©taill√©"):
            report_data = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "summary_metrics": {
                    "total_deforestation": float(total_deforestation),
                    "annual_rate": float(annual_rate),
                    "population_growth": float(
                        df_enriched["Population"].iloc[-1] - df_enriched["Population"].iloc[0]
                    ),
                    "agricultural_expansion": float(
                        df_enriched["Cultures Annuelles (CA)"].iloc[-1]
                        - df_enriched["Cultures Annuelles (CA)"].iloc[0]
                    ),
                },
            }
            report_json = json.dumps(report_data, indent=2)
            st.download_button(
                label="üì• T√©l√©charger les donn√©es du rapport (JSON)",
                data=report_json,
                file_name=f"rapport_deforestation_{datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json",
            )
            st.success("‚úÖ Rapport g√©n√©r√© (structure JSON).")


# =============================================================================
# EX√âCUTION
# =============================================================================

if __name__ == "__main__":
    main()
